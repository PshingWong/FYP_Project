{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72b78d86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyLDAvis in /Users/pshing/opt/anaconda3/lib/python3.9/site-packages (3.4.0)\n",
      "Requirement already satisfied: numpy>=1.22.0 in /Users/pshing/opt/anaconda3/lib/python3.9/site-packages (from pyLDAvis) (1.24.2)\n",
      "Requirement already satisfied: scipy in /Users/pshing/opt/anaconda3/lib/python3.9/site-packages (from pyLDAvis) (1.9.1)\n",
      "Requirement already satisfied: joblib>=1.2.0 in /Users/pshing/opt/anaconda3/lib/python3.9/site-packages (from pyLDAvis) (1.2.0)\n",
      "Requirement already satisfied: pandas>=1.3.4 in /Users/pshing/opt/anaconda3/lib/python3.9/site-packages (from pyLDAvis) (1.4.4)\n",
      "Requirement already satisfied: numexpr in /Users/pshing/opt/anaconda3/lib/python3.9/site-packages (from pyLDAvis) (2.8.3)\n",
      "Requirement already satisfied: jinja2 in /Users/pshing/opt/anaconda3/lib/python3.9/site-packages (from pyLDAvis) (2.11.3)\n",
      "Requirement already satisfied: gensim in /Users/pshing/opt/anaconda3/lib/python3.9/site-packages (from pyLDAvis) (4.1.2)\n",
      "Requirement already satisfied: funcy in /Users/pshing/opt/anaconda3/lib/python3.9/site-packages (from pyLDAvis) (1.18)\n",
      "Requirement already satisfied: setuptools in /Users/pshing/opt/anaconda3/lib/python3.9/site-packages (from pyLDAvis) (63.4.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.0 in /Users/pshing/opt/anaconda3/lib/python3.9/site-packages (from pyLDAvis) (1.0.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/pshing/opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.3.4->pyLDAvis) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Users/pshing/opt/anaconda3/lib/python3.9/site-packages (from pandas>=1.3.4->pyLDAvis) (2022.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /Users/pshing/opt/anaconda3/lib/python3.9/site-packages (from scikit-learn>=1.0.0->pyLDAvis) (2.2.0)\n",
      "Requirement already satisfied: smart-open>=1.8.1 in /Users/pshing/opt/anaconda3/lib/python3.9/site-packages (from gensim->pyLDAvis) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /Users/pshing/opt/anaconda3/lib/python3.9/site-packages (from jinja2->pyLDAvis) (2.0.1)\n",
      "Requirement already satisfied: packaging in /Users/pshing/opt/anaconda3/lib/python3.9/site-packages (from numexpr->pyLDAvis) (21.3)\n",
      "Requirement already satisfied: six>=1.5 in /Users/pshing/opt/anaconda3/lib/python3.9/site-packages (from python-dateutil>=2.8.1->pandas>=1.3.4->pyLDAvis) (1.16.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/pshing/opt/anaconda3/lib/python3.9/site-packages (from packaging->numexpr->pyLDAvis) (3.0.9)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyLDAvis\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2c15ec92",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pshing/opt/anaconda3/lib/python3.9/site-packages/gensim/matutils.py:22: DeprecationWarning: Please use `triu` from the `scipy.linalg` namespace, the `scipy.linalg.special_matrices` namespace is deprecated.\n",
      "  from scipy.linalg.special_matrices import triu\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from nltk.corpus import stopwords\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "import pyLDAvis.sklearn\n",
    "from gensim import matutils, models, corpora\n",
    "import scipy.sparse\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1968578f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Keywords: 0.052*\"files\" + 0.052*\"vera\" + 0.046*\"fact\" + 0.046*\"check\" + 0.028*\"covid19\" + 0.018*\"false\" + 0.010*\"gates\" + 0.010*\"politifact\" + 0.008*\"lead\" + 0.008*\"bill\"\n",
      "Topic: 1 \n",
      "Keywords: 0.042*\"covid19\" + 0.031*\"check\" + 0.027*\"fact\" + 0.020*\"politifact\" + 0.016*\"afp\" + 0.009*\"vaccine\" + 0.007*\"hoax\" + 0.007*\"factly\" + 0.006*\"video\" + 0.006*\"bill\"\n",
      "Topic: 2 \n",
      "Keywords: 0.045*\"check\" + 0.042*\"fact\" + 0.019*\"video\" + 0.017*\"afp\" + 0.016*\"covid19\" + 0.015*\"lead\" + 0.015*\"stories\" + 0.012*\"coronavirus\" + 0.011*\"lanka\" + 0.011*\"sri\"\n",
      "Topic: 3 \n",
      "Keywords: 0.069*\"fact\" + 0.069*\"check\" + 0.056*\"afp\" + 0.030*\"covid19\" + 0.017*\"shows\" + 0.015*\"video\" + 0.013*\"photo\" + 0.012*\"online\" + 0.012*\"health\" + 0.011*\"pandemic\"\n",
      "Topic: 4 \n",
      "Keywords: 0.049*\"coronavirus\" + 0.031*\"check\" + 0.029*\"fact\" + 0.019*\"stories\" + 0.019*\"lead\" + 0.015*\"politifact\" + 0.011*\"covid19\" + 0.011*\"false\" + 0.009*\"nobel\" + 0.007*\"trump\"\n",
      "Topic: 5 \n",
      "Keywords: 0.035*\"shared\" + 0.033*\"factly\" + 0.027*\"old\" + 0.024*\"video\" + 0.022*\"falsely\" + 0.014*\"lockdown\" + 0.012*\"covid19\" + 0.009*\"image\" + 0.009*\"false\" + 0.008*\"coronavirus\"\n",
      "Topic: 6 \n",
      "Keywords: 0.019*\"factly\" + 0.014*\"covid19\" + 0.013*\"false\" + 0.009*\"due\" + 0.009*\"shared\" + 0.008*\"coronavirus\" + 0.008*\"lockdown\" + 0.007*\"claiming\" + 0.006*\"old\" + 0.006*\"message\"\n",
      "Topic: 7 \n",
      "Keywords: 0.041*\"covid19\" + 0.020*\"false\" + 0.017*\"politifact\" + 0.011*\"–\" + 0.009*\"coronavirus\" + 0.009*\"check\" + 0.009*\"factly\" + 0.008*\"claim\" + 0.008*\"us\" + 0.007*\"africa\"\n",
      "Topic: 8 \n",
      "Keywords: 0.024*\"check\" + 0.022*\"coronavirus\" + 0.021*\"fact\" + 0.015*\"covid19\" + 0.011*\"stories\" + 0.011*\"lead\" + 0.010*\"politifact\" + 0.009*\"claim\" + 0.009*\"false\" + 0.008*\"house\"\n",
      "Topic: 9 \n",
      "Keywords: 0.026*\"false\" + 0.024*\"covid19\" + 0.022*\"check\" + 0.020*\"fact\" + 0.016*\"coronavirus\" + 0.009*\"news\" + 0.008*\"video\" + 0.008*\"workers\" + 0.008*\"politifact\" + 0.008*\"viral\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pshing/opt/anaconda3/lib/python3.9/site-packages/pyLDAvis/_prepare.py:243: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('en_False_tran.csv')\n",
    "\n",
    "# Define stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Define preprocessing function for source_title column\n",
    "def preprocess_text(text):\n",
    "    words = text.lower().split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Apply preprocessing to source_title column\n",
    "data['processed_text'] = data['source_title'].apply(preprocess_text)\n",
    "\n",
    "# Create document-term matrix\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(data['processed_text'])\n",
    "\n",
    "processed_docs = data['processed_text'].apply(lambda x: x.split())\n",
    "\n",
    "# Create the gensim Dictionary object\n",
    "Dictionary = corpora.Dictionary(processed_docs)\n",
    "\n",
    "# Convert the preprocessed documents into a gensim corpus\n",
    "corpus = [Dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "\n",
    "# Train the LDA model\n",
    "lda_model = models.LdaModel(corpus=corpus, num_topics=10, id2word=Dictionary, passes=10, random_state=42)\n",
    "\n",
    "# Print the top 10 keywords for each topic\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nKeywords: {}\".format(idx, topic))\n",
    "\n",
    "# Visualize the topics\n",
    "lda_visualization = gensimvis.prepare(lda_model, corpus, Dictionary)\n",
    "\n",
    "# Save the visualization to an HTML file\n",
    "pyLDAvis.save_html(lda_visualization, 'en_title.html')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "18a8775f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Keywords: 0.027*\"false\" + 0.019*\"checked\" + 0.015*\"gates\" + 0.014*\"coronavirus\" + 0.011*\"bill\" + 0.010*\"covid19\" + 0.007*\"damn\" + 0.007*\"statements\" + 0.007*\"efe\" + 0.007*\"5g\"\n",
      "Topic: 1 \n",
      "Keywords: 0.030*\"false\" + 0.020*\"coronavirus\" + 0.019*\"covid19\" + 0.017*\"cure\" + 0.012*\"covid\" + 0.009*\"chlorine\" + 0.009*\"dioxide\" + 0.009*\"checked\" + 0.008*\"19\" + 0.007*\"new\"\n",
      "Topic: 2 \n",
      "Keywords: 0.035*\"covid19\" + 0.016*\"coronavirus\" + 0.014*\"nocomacuento\" + 0.010*\"efe\" + 0.009*\"vaccine\" + 0.008*\"colombiacheck\" + 0.008*\"check\" + 0.008*\"food\" + 0.008*\"tasuku\" + 0.008*\"honjo\"\n",
      "Topic: 3 \n",
      "Keywords: 0.059*\"chair\" + 0.058*\"empty\" + 0.057*\"detector\" + 0.032*\"covid19\" + 0.017*\"coronavirus\" + 0.010*\"newtral\" + 0.010*\"new\" + 0.008*\"vaccine\" + 0.007*\"non\" + 0.006*\"efe\"\n",
      "Topic: 4 \n",
      "Keywords: 0.028*\"coronavirus\" + 0.017*\"false\" + 0.015*\"newtral\" + 0.011*\"covid19\" + 0.011*\"video\" + 0.007*\"water\" + 0.007*\"government\" + 0.007*\"cursed\" + 0.007*\"damn\" + 0.007*\"cure\"\n",
      "Topic: 5 \n",
      "Keywords: 0.036*\"coronavirus\" + 0.031*\"false\" + 0.019*\"covid19\" + 0.011*\"efe\" + 0.010*\"newtral\" + 0.010*\"cursed\" + 0.007*\"verified\" + 0.006*\"bill\" + 0.006*\"gates\" + 0.005*\"agency\"\n",
      "Topic: 6 \n",
      "Keywords: 0.055*\"covid\" + 0.046*\"19\" + 0.045*\"ecuador\" + 0.037*\"lies\" + 0.020*\"covid19\" + 0.018*\"false\" + 0.013*\"coronavirus\" + 0.010*\"checked\" + 0.009*\"video\" + 0.009*\"newtral\"\n",
      "Topic: 7 \n",
      "Keywords: 0.024*\"coronavirus\" + 0.023*\"covid19\" + 0.021*\"efe\" + 0.020*\"false\" + 0.019*\"newtral\" + 0.014*\"vaccine\" + 0.011*\"use\" + 0.010*\"checked\" + 0.009*\"agency\" + 0.009*\"spain\"\n",
      "Topic: 8 \n",
      "Keywords: 0.026*\"coronavirus\" + 0.012*\"false\" + 0.012*\"covid19\" + 0.011*\"cursed\" + 0.011*\"5g\" + 0.011*\"eye\" + 0.009*\"checked\" + 0.009*\"video\" + 0.009*\"colombiacheck\" + 0.009*\"2019\"\n",
      "Topic: 9 \n",
      "Keywords: 0.027*\"coronavirus\" + 0.019*\"efe\" + 0.014*\"nocomacuento\" + 0.011*\"newtral\" + 0.010*\"covid19\" + 0.009*\"la\" + 0.009*\"nación\" + 0.009*\"states\" + 0.008*\"image\" + 0.008*\"agency\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pshing/opt/anaconda3/lib/python3.9/site-packages/pyLDAvis/_prepare.py:243: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('es_False_tran.csv')\n",
    "\n",
    "# Define stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Define preprocessing function for source_title column\n",
    "def preprocess_text(text):\n",
    "    words = text.lower().split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Apply preprocessing to source_title column\n",
    "data['processed_text'] = data['source_title_translated'].apply(preprocess_text)\n",
    "\n",
    "# Create document-term matrix\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(data['processed_text'])\n",
    "\n",
    "processed_docs = data['processed_text'].apply(lambda x: x.split())\n",
    "\n",
    "# Create the gensim Dictionary object\n",
    "Dictionary = corpora.Dictionary(processed_docs)\n",
    "\n",
    "# Convert the preprocessed documents into a gensim corpus\n",
    "corpus = [Dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "\n",
    "# Train the LDA model\n",
    "lda_model = models.LdaModel(corpus=corpus, num_topics=10, id2word=Dictionary, passes=10, random_state=42)\n",
    "\n",
    "# Print the top 10 keywords for each topic\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nKeywords: {}\".format(idx, topic))\n",
    "\n",
    "# Visualize the topics\n",
    "lda_visualization = gensimvis.prepare(lda_model, corpus, Dictionary)\n",
    "\n",
    "# Save the visualization to an HTML file\n",
    "pyLDAvis.save_html(lda_visualization, 'es_title.html')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ad2da27f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Keywords: 0.028*\"facts\" + 0.018*\"china\" + 0.017*\"false\" + 0.014*\"masks\" + 0.014*\"video\" + 0.009*\"pandemic\" + 0.009*\"coronaviruses\" + 0.009*\"government\" + 0.009*\"photo\" + 0.009*\"covid19\"\n",
      "Topic: 1 \n",
      "Keywords: 0.053*\"covid19\" + 0.035*\"false\" + 0.030*\"facts\" + 0.024*\"deaths\" + 0.024*\"lupa\" + 0.024*\"agency\" + 0.012*\"see\" + 0.012*\"death\" + 0.012*\"thousand\" + 0.011*\"coronavirus\"\n",
      "Topic: 2 \n",
      "Keywords: 0.035*\"pandemic\" + 0.028*\"covid19\" + 0.024*\"checked\" + 0.022*\"agency\" + 0.020*\"facts\" + 0.016*\"photo\" + 0.016*\"check\" + 0.016*\"deaths\" + 0.016*\"lupa\" + 0.015*\"video\"\n",
      "Topic: 3 \n",
      "Keywords: 0.042*\"-\" + 0.042*\"observer\" + 0.035*\"fact\" + 0.035*\"check\" + 0.018*\"coronavirus\" + 0.012*\"lupa\" + 0.011*\"agency\" + 0.010*\"coronaviruses\" + 0.010*\"sp\" + 0.010*\"garlic\"\n",
      "Topic: 4 \n",
      "Keywords: 0.024*\"agency\" + 0.024*\"lupa\" + 0.019*\"fake\" + 0.019*\"created\" + 0.019*\"checked\" + 0.017*\"coronavirus\" + 0.015*\"facts\" + 0.010*\"new\" + 0.010*\"say\" + 0.010*\"nobel\"\n",
      "Topic: 5 \n",
      "Keywords: 0.028*\"covid19\" + 0.020*\"facts\" + 0.019*\"coronavirus\" + 0.018*\"agency\" + 0.018*\"lupa\" + 0.014*\"checked\" + 0.014*\"patients\" + 0.014*\"new\" + 0.014*\"fake\" + 0.011*\"hospitals\"\n",
      "Topic: 6 \n",
      "Keywords: 0.041*\"lupa\" + 0.038*\"agency\" + 0.032*\"false\" + 0.027*\"covid19\" + 0.023*\"checked\" + 0.018*\"facts\" + 0.018*\"old\" + 0.015*\"see\" + 0.013*\"video\" + 0.011*\"empty\"\n",
      "Topic: 7 \n",
      "Keywords: 0.043*\"false\" + 0.034*\"covid19\" + 0.029*\"lupa\" + 0.029*\"facts\" + 0.026*\"checked\" + 0.026*\"agency\" + 0.016*\"patients\" + 0.013*\"hospital\" + 0.013*\"fake\" + 0.010*\"video\"\n",
      "Topic: 8 \n",
      "Keywords: 0.074*\"agency\" + 0.070*\"lupa\" + 0.054*\"checked\" + 0.043*\"covid19\" + 0.039*\"false\" + 0.013*\"video\" + 0.012*\"pandemic\" + 0.011*\"fake\" + 0.010*\"see\" + 0.009*\"death\"\n",
      "Topic: 9 \n",
      "Keywords: 0.028*\"covid19\" + 0.028*\"false\" + 0.027*\"lupa\" + 0.024*\"facts\" + 0.024*\"agency\" + 0.018*\"health\" + 0.015*\"photo\" + 0.015*\"see\" + 0.012*\"rio\" + 0.010*\"video\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pshing/opt/anaconda3/lib/python3.9/site-packages/pyLDAvis/_prepare.py:243: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('pt_False_tran.csv')\n",
    "\n",
    "# Define stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Define preprocessing function for source_title column\n",
    "def preprocess_text(text):\n",
    "    words = text.lower().split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Apply preprocessing to source_title column\n",
    "data['processed_text'] = data['source_title_translated'].apply(preprocess_text)\n",
    "\n",
    "# Create document-term matrix\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(data['processed_text'])\n",
    "\n",
    "processed_docs = data['processed_text'].apply(lambda x: x.split())\n",
    "\n",
    "# Create the gensim Dictionary object\n",
    "Dictionary = corpora.Dictionary(processed_docs)\n",
    "\n",
    "# Convert the preprocessed documents into a gensim corpus\n",
    "corpus = [Dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "\n",
    "# Train the LDA model\n",
    "lda_model = models.LdaModel(corpus=corpus, num_topics=10, id2word=Dictionary, passes=10, random_state=42)\n",
    "\n",
    "# Print the top 10 keywords for each topic\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nKeywords: {}\".format(idx, topic))\n",
    "\n",
    "# Visualize the topics\n",
    "lda_visualization = gensimvis.prepare(lda_model, corpus, Dictionary)\n",
    "\n",
    "# Save the visualization to an HTML file\n",
    "pyLDAvis.save_html(lda_visualization, 'pt_title.html')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ece5b2fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Keywords: 0.045*\"no,\" + 0.025*\"remotely\" + 0.023*\"factual\" + 0.020*\"coronavirus\" + 0.015*\"liberation\" + 0.015*\"china\" + 0.015*\"de\" + 0.015*\"macron\" + 0.010*\"france\" + 0.010*\"masks\"\n",
      "Topic: 1 \n",
      "Keywords: 0.035*\"agency\" + 0.035*\"false\" + 0.022*\"science\" + 0.021*\"covvi19\" + 0.021*\"non\" + 0.015*\"didier\" + 0.015*\"raoult\" + 0.015*\"created\" + 0.015*\"sciential\" + 0.015*\"china\"\n",
      "Topic: 2 \n",
      "Keywords: 0.047*\"coronavirus\" + 0.033*\"europe\" + 0.025*\"factual\" + 0.019*\"masks\" + 0.014*\"scenes\" + 0.014*\"manifestations\" + 0.014*\"panic\" + 0.010*\"french\" + 0.010*\"file\" + 0.010*\"false\"\n",
      "Topic: 3 \n",
      "Keywords: 0.054*\"coronavirus\" + 0.027*\"china\" + 0.027*\"popular\" + 0.027*\"dish\" + 0.027*\"autopsy\" + 0.027*\"soup\" + 0.027*\"rumor\" + 0.027*\"bats\" + 0.018*\"false\" + 0.009*\"radiocanadaca\"\n",
      "Topic: 4 \n",
      "Keywords: 0.036*\"factual\" + 0.023*\"false\" + 0.023*\"coronavirus\" + 0.018*\"macron\" + 0.014*\"no,\" + 0.014*\"liberation\" + 0.014*\"extras\" + 0.014*\"applauded\" + 0.014*\"pantin\" + 0.009*\"april\"\n",
      "Topic: 5 \n",
      "Keywords: 0.026*\"factual\" + 0.021*\"coronavirus\" + 0.017*\"false\" + 0.016*\"vaccine\" + 0.016*\"liberation\" + 0.011*\"no,\" + 0.011*\"april\" + 0.011*\"new\" + 0.011*\"states\" + 0.011*\"video\"\n",
      "Topic: 6 \n",
      "Keywords: 0.022*\"19\" + 0.015*\"coronavirus\" + 0.015*\"raoult\" + 0.015*\"africa\" + 0.015*\"false\" + 0.008*\"china\" + 0.008*\"5g\" + 0.008*\"created\" + 0.008*\"viral\" + 0.008*\"united\"\n",
      "Topic: 7 \n",
      "Keywords: 0.038*\"factual\" + 0.034*\"coronavirus\" + 0.030*\"false\" + 0.015*\"video\" + 0.012*\"vaccine\" + 0.012*\"china\" + 0.012*\"proven\" + 0.012*\"19\" + 0.008*\"agency\" + 0.008*\"covid19\"\n",
      "Topic: 8 \n",
      "Keywords: 0.036*\"coronavirus\" + 0.026*\"liberation\" + 0.021*\"covid\" + 0.021*\"19\" + 0.021*\"factual\" + 0.016*\"true\" + 0.011*\"false\" + 0.011*\"radiocanadaca\" + 0.011*\"made\" + 0.011*\"hydroxychloroquine\"\n",
      "Topic: 9 \n",
      "Keywords: 0.029*\"factual\" + 0.022*\"no,\" + 0.015*\"video\" + 0.015*\"covidorganics\" + 0.015*\"show\" + 0.015*\"hospital\" + 0.015*\"false\" + 0.008*\"liberation\" + 0.008*\"france\" + 0.008*\"19\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pshing/opt/anaconda3/lib/python3.9/site-packages/pyLDAvis/_prepare.py:243: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('fr_False_tran.csv')\n",
    "\n",
    "# Define stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Define preprocessing function for source_title column\n",
    "def preprocess_text(text):\n",
    "    words = text.lower().split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Apply preprocessing to source_title column\n",
    "data['processed_text'] = data['source_title_translated'].apply(preprocess_text)\n",
    "\n",
    "# Create document-term matrix\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(data['processed_text'])\n",
    "\n",
    "processed_docs = data['processed_text'].apply(lambda x: x.split())\n",
    "\n",
    "# Create the gensim Dictionary object\n",
    "Dictionary = corpora.Dictionary(processed_docs)\n",
    "\n",
    "# Convert the preprocessed documents into a gensim corpus\n",
    "corpus = [Dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "\n",
    "# Train the LDA model\n",
    "lda_model = models.LdaModel(corpus=corpus, num_topics=10, id2word=Dictionary, passes=10, random_state=42)\n",
    "\n",
    "# Print the top 10 keywords for each topic\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nKeywords: {}\".format(idx, topic))\n",
    "\n",
    "# Visualize the topics\n",
    "lda_visualization = gensimvis.prepare(lda_model, corpus, Dictionary)\n",
    "\n",
    "# Save the visualization to an HTML file\n",
    "pyLDAvis.save_html(lda_visualization, 'fr_title.html')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f72b98b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Keywords: 0.011*\"2020\" + 0.008*\"news\" + 0.008*\"april\" + 0.007*\"covid19\" + 0.007*\"coronavirus\" + 0.006*\"deaths\" + 0.006*\"post\" + 0.006*\"may\" + 0.006*\"us\" + 0.005*\"video\"\n",
      "Topic: 1 \n",
      "Keywords: 0.008*\"covid19\" + 0.006*\"vera\" + 0.006*\"news\" + 0.006*\"information\" + 0.006*\"–\" + 0.006*\"media\" + 0.006*\"comments\" + 0.006*\"files\" + 0.006*\"post\" + 0.006*\"n\"\n",
      "Topic: 2 \n",
      "Keywords: 0.012*\"video\" + 0.007*\"2020\" + 0.005*\"state\" + 0.005*\"us\" + 0.005*\"also\" + 0.004*\"budget\" + 0.004*\"may\" + 0.003*\"viral\" + 0.003*\"read\" + 0.003*\"found\"\n",
      "Topic: 3 \n",
      "Keywords: 0.013*\"video\" + 0.009*\"covid19\" + 0.008*\"also\" + 0.008*\"coronavirus\" + 0.006*\"claim\" + 0.005*\"read\" + 0.005*\"said\" + 0.005*\"2020\" + 0.004*\"lockdown\" + 0.004*\"virus\"\n",
      "Topic: 4 \n",
      "Keywords: 0.017*\"afp\" + 0.009*\"content\" + 0.008*\"video\" + 0.008*\"post\" + 0.007*\"website\" + 0.007*\"media\" + 0.006*\"also\" + 0.006*\"facebook\" + 0.006*\"rights\" + 0.006*\"use\"\n",
      "Topic: 5 \n",
      "Keywords: 0.016*\"pesacheck\" + 0.013*\"public\" + 0.011*\"media\" + 0.009*\"facebook\" + 0.009*\"covid19\" + 0.008*\"social\" + 0.006*\"post\" + 0.006*\"factchecking\" + 0.006*\"written\" + 0.006*\"information\"\n",
      "Topic: 6 \n",
      "Keywords: 0.012*\"covid19\" + 0.009*\"2020\" + 0.008*\"coronavirus\" + 0.007*\"health\" + 0.006*\"said\" + 0.006*\"post\" + 0.005*\"april\" + 0.005*\"people\" + 0.004*\"may\" + 0.004*\"us\"\n",
      "Topic: 7 \n",
      "Keywords: 0.005*\"said\" + 0.005*\"vaccine\" + 0.004*\"health\" + 0.003*\"gates\" + 0.003*\"state\" + 0.003*\"news\" + 0.003*\"may\" + 0.003*\"covid19\" + 0.003*\"countries\" + 0.003*\"vaccines\"\n",
      "Topic: 8 \n",
      "Keywords: 0.010*\"2020\" + 0.009*\"coronavirus\" + 0.008*\"covid19\" + 0.007*\"us\" + 0.006*\"facebook\" + 0.005*\"post\" + 0.005*\"gates\" + 0.005*\"bill\" + 0.005*\"check\" + 0.005*\"may\"\n",
      "Topic: 9 \n",
      "Keywords: 0.008*\"covid19\" + 0.008*\"coronavirus\" + 0.007*\"us\" + 0.006*\"claim\" + 0.006*\"said\" + 0.006*\"news\" + 0.006*\"also\" + 0.005*\"vaccine\" + 0.005*\"read\" + 0.005*\"april\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pshing/opt/anaconda3/lib/python3.9/site-packages/pyLDAvis/_prepare.py:243: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('en_False_tran.csv')\n",
    "\n",
    "# Define stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Define preprocessing function for source_title column\n",
    "def preprocess_text(text):\n",
    "    words = text.lower().split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Apply preprocessing to source_title column\n",
    "data['processed_text'] = data['content_text'].apply(preprocess_text)\n",
    "\n",
    "# Create document-term matrix\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(data['processed_text'])\n",
    "\n",
    "processed_docs = data['processed_text'].apply(lambda x: x.split())\n",
    "\n",
    "# Create the gensim Dictionary object\n",
    "Dictionary = corpora.Dictionary(processed_docs)\n",
    "\n",
    "# Convert the preprocessed documents into a gensim corpus\n",
    "corpus = [Dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "\n",
    "# Train the LDA model\n",
    "lda_model = models.LdaModel(corpus=corpus, num_topics=10, id2word=Dictionary, passes=10, random_state=42)\n",
    "\n",
    "# Print the top 10 keywords for each topic\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nKeywords: {}\".format(idx, topic))\n",
    "\n",
    "# Visualize the topics\n",
    "lda_visualization = gensimvis.prepare(lda_model, corpus, Dictionary)\n",
    "\n",
    "# Save the visualization to an HTML file\n",
    "pyLDAvis.save_html(lda_visualization, 'en_content.html')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5f777dcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Keywords: 0.027*\"false\" + 0.019*\"checked\" + 0.015*\"gates\" + 0.014*\"coronavirus\" + 0.011*\"bill\" + 0.010*\"covid19\" + 0.007*\"damn\" + 0.007*\"statements\" + 0.007*\"efe\" + 0.007*\"5g\"\n",
      "Topic: 1 \n",
      "Keywords: 0.030*\"false\" + 0.020*\"coronavirus\" + 0.019*\"covid19\" + 0.017*\"cure\" + 0.012*\"covid\" + 0.009*\"chlorine\" + 0.009*\"dioxide\" + 0.009*\"checked\" + 0.008*\"19\" + 0.007*\"new\"\n",
      "Topic: 2 \n",
      "Keywords: 0.035*\"covid19\" + 0.016*\"coronavirus\" + 0.014*\"nocomacuento\" + 0.010*\"efe\" + 0.009*\"vaccine\" + 0.008*\"colombiacheck\" + 0.008*\"check\" + 0.008*\"food\" + 0.008*\"tasuku\" + 0.008*\"honjo\"\n",
      "Topic: 3 \n",
      "Keywords: 0.059*\"chair\" + 0.058*\"empty\" + 0.057*\"detector\" + 0.032*\"covid19\" + 0.017*\"coronavirus\" + 0.010*\"newtral\" + 0.010*\"new\" + 0.008*\"vaccine\" + 0.007*\"non\" + 0.006*\"efe\"\n",
      "Topic: 4 \n",
      "Keywords: 0.028*\"coronavirus\" + 0.017*\"false\" + 0.015*\"newtral\" + 0.011*\"covid19\" + 0.011*\"video\" + 0.007*\"water\" + 0.007*\"government\" + 0.007*\"cursed\" + 0.007*\"damn\" + 0.007*\"cure\"\n",
      "Topic: 5 \n",
      "Keywords: 0.036*\"coronavirus\" + 0.031*\"false\" + 0.019*\"covid19\" + 0.011*\"efe\" + 0.010*\"newtral\" + 0.010*\"cursed\" + 0.007*\"verified\" + 0.006*\"bill\" + 0.006*\"gates\" + 0.005*\"agency\"\n",
      "Topic: 6 \n",
      "Keywords: 0.055*\"covid\" + 0.046*\"19\" + 0.045*\"ecuador\" + 0.037*\"lies\" + 0.020*\"covid19\" + 0.018*\"false\" + 0.013*\"coronavirus\" + 0.010*\"checked\" + 0.009*\"video\" + 0.009*\"newtral\"\n",
      "Topic: 7 \n",
      "Keywords: 0.024*\"coronavirus\" + 0.023*\"covid19\" + 0.021*\"efe\" + 0.020*\"false\" + 0.019*\"newtral\" + 0.014*\"vaccine\" + 0.011*\"use\" + 0.010*\"checked\" + 0.009*\"agency\" + 0.009*\"spain\"\n",
      "Topic: 8 \n",
      "Keywords: 0.026*\"coronavirus\" + 0.012*\"false\" + 0.012*\"covid19\" + 0.011*\"cursed\" + 0.011*\"5g\" + 0.011*\"eye\" + 0.009*\"checked\" + 0.009*\"video\" + 0.009*\"colombiacheck\" + 0.009*\"2019\"\n",
      "Topic: 9 \n",
      "Keywords: 0.027*\"coronavirus\" + 0.019*\"efe\" + 0.014*\"nocomacuento\" + 0.011*\"newtral\" + 0.010*\"covid19\" + 0.009*\"la\" + 0.009*\"nación\" + 0.009*\"states\" + 0.008*\"image\" + 0.008*\"agency\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pshing/opt/anaconda3/lib/python3.9/site-packages/pyLDAvis/_prepare.py:243: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('es_False_tran.csv')\n",
    "\n",
    "# Define stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Define preprocessing function for source_title column\n",
    "def preprocess_text(text):\n",
    "    words = text.lower().split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Apply preprocessing to source_title column\n",
    "data['processed_text'] = data['source_title_translated'].apply(preprocess_text)\n",
    "\n",
    "# Create document-term matrix\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(data['processed_text'])\n",
    "\n",
    "processed_docs = data['processed_text'].apply(lambda x: x.split())\n",
    "\n",
    "# Create the gensim Dictionary object\n",
    "Dictionary = corpora.Dictionary(processed_docs)\n",
    "\n",
    "# Convert the preprocessed documents into a gensim corpus\n",
    "corpus = [Dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "\n",
    "# Train the LDA model\n",
    "lda_model = models.LdaModel(corpus=corpus, num_topics=10, id2word=Dictionary, passes=10, random_state=42)\n",
    "\n",
    "# Print the top 10 keywords for each topic\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nKeywords: {}\".format(idx, topic))\n",
    "\n",
    "# Visualize the topics\n",
    "lda_visualization = gensimvis.prepare(lda_model, corpus, Dictionary)\n",
    "\n",
    "# Save the visualization to an HTML file\n",
    "pyLDAvis.save_html(lda_visualization, 'es_content.html')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "be219c8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Keywords: 0.028*\"facts\" + 0.018*\"china\" + 0.017*\"false\" + 0.014*\"masks\" + 0.014*\"video\" + 0.009*\"pandemic\" + 0.009*\"coronaviruses\" + 0.009*\"government\" + 0.009*\"photo\" + 0.009*\"covid19\"\n",
      "Topic: 1 \n",
      "Keywords: 0.053*\"covid19\" + 0.035*\"false\" + 0.030*\"facts\" + 0.024*\"deaths\" + 0.024*\"lupa\" + 0.024*\"agency\" + 0.012*\"see\" + 0.012*\"death\" + 0.012*\"thousand\" + 0.011*\"coronavirus\"\n",
      "Topic: 2 \n",
      "Keywords: 0.035*\"pandemic\" + 0.028*\"covid19\" + 0.024*\"checked\" + 0.022*\"agency\" + 0.020*\"facts\" + 0.016*\"photo\" + 0.016*\"check\" + 0.016*\"deaths\" + 0.016*\"lupa\" + 0.015*\"video\"\n",
      "Topic: 3 \n",
      "Keywords: 0.042*\"-\" + 0.042*\"observer\" + 0.035*\"fact\" + 0.035*\"check\" + 0.018*\"coronavirus\" + 0.012*\"lupa\" + 0.011*\"agency\" + 0.010*\"coronaviruses\" + 0.010*\"sp\" + 0.010*\"garlic\"\n",
      "Topic: 4 \n",
      "Keywords: 0.024*\"agency\" + 0.024*\"lupa\" + 0.019*\"fake\" + 0.019*\"created\" + 0.019*\"checked\" + 0.017*\"coronavirus\" + 0.015*\"facts\" + 0.010*\"new\" + 0.010*\"say\" + 0.010*\"nobel\"\n",
      "Topic: 5 \n",
      "Keywords: 0.028*\"covid19\" + 0.020*\"facts\" + 0.019*\"coronavirus\" + 0.018*\"agency\" + 0.018*\"lupa\" + 0.014*\"checked\" + 0.014*\"patients\" + 0.014*\"new\" + 0.014*\"fake\" + 0.011*\"hospitals\"\n",
      "Topic: 6 \n",
      "Keywords: 0.041*\"lupa\" + 0.038*\"agency\" + 0.032*\"false\" + 0.027*\"covid19\" + 0.023*\"checked\" + 0.018*\"facts\" + 0.018*\"old\" + 0.015*\"see\" + 0.013*\"video\" + 0.011*\"empty\"\n",
      "Topic: 7 \n",
      "Keywords: 0.043*\"false\" + 0.034*\"covid19\" + 0.029*\"lupa\" + 0.029*\"facts\" + 0.026*\"checked\" + 0.026*\"agency\" + 0.016*\"patients\" + 0.013*\"hospital\" + 0.013*\"fake\" + 0.010*\"video\"\n",
      "Topic: 8 \n",
      "Keywords: 0.074*\"agency\" + 0.070*\"lupa\" + 0.054*\"checked\" + 0.043*\"covid19\" + 0.039*\"false\" + 0.013*\"video\" + 0.012*\"pandemic\" + 0.011*\"fake\" + 0.010*\"see\" + 0.009*\"death\"\n",
      "Topic: 9 \n",
      "Keywords: 0.028*\"covid19\" + 0.028*\"false\" + 0.027*\"lupa\" + 0.024*\"facts\" + 0.024*\"agency\" + 0.018*\"health\" + 0.015*\"photo\" + 0.015*\"see\" + 0.012*\"rio\" + 0.010*\"video\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pshing/opt/anaconda3/lib/python3.9/site-packages/pyLDAvis/_prepare.py:243: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('pt_False_tran.csv')\n",
    "\n",
    "# Define stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Define preprocessing function for source_title column\n",
    "def preprocess_text(text):\n",
    "    words = text.lower().split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Apply preprocessing to source_title column\n",
    "data['processed_text'] = data['source_title_translated'].apply(preprocess_text)\n",
    "\n",
    "# Create document-term matrix\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(data['processed_text'])\n",
    "\n",
    "processed_docs = data['processed_text'].apply(lambda x: x.split())\n",
    "\n",
    "# Create the gensim Dictionary object\n",
    "Dictionary = corpora.Dictionary(processed_docs)\n",
    "\n",
    "# Convert the preprocessed documents into a gensim corpus\n",
    "corpus = [Dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "\n",
    "# Train the LDA model\n",
    "lda_model = models.LdaModel(corpus=corpus, num_topics=10, id2word=Dictionary, passes=10, random_state=42)\n",
    "\n",
    "# Print the top 10 keywords for each topic\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nKeywords: {}\".format(idx, topic))\n",
    "\n",
    "# Visualize the topics\n",
    "lda_visualization = gensimvis.prepare(lda_model, corpus, Dictionary)\n",
    "\n",
    "# Save the visualization to an HTML file\n",
    "pyLDAvis.save_html(lda_visualization, 'pt_content.html')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "061ed4e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Keywords: 0.045*\"no,\" + 0.025*\"remotely\" + 0.023*\"factual\" + 0.020*\"coronavirus\" + 0.015*\"liberation\" + 0.015*\"china\" + 0.015*\"de\" + 0.015*\"macron\" + 0.010*\"france\" + 0.010*\"masks\"\n",
      "Topic: 1 \n",
      "Keywords: 0.035*\"agency\" + 0.035*\"false\" + 0.022*\"science\" + 0.021*\"covvi19\" + 0.021*\"non\" + 0.015*\"didier\" + 0.015*\"raoult\" + 0.015*\"created\" + 0.015*\"sciential\" + 0.015*\"china\"\n",
      "Topic: 2 \n",
      "Keywords: 0.047*\"coronavirus\" + 0.033*\"europe\" + 0.025*\"factual\" + 0.019*\"masks\" + 0.014*\"scenes\" + 0.014*\"manifestations\" + 0.014*\"panic\" + 0.010*\"french\" + 0.010*\"file\" + 0.010*\"false\"\n",
      "Topic: 3 \n",
      "Keywords: 0.054*\"coronavirus\" + 0.027*\"china\" + 0.027*\"popular\" + 0.027*\"dish\" + 0.027*\"autopsy\" + 0.027*\"soup\" + 0.027*\"rumor\" + 0.027*\"bats\" + 0.018*\"false\" + 0.009*\"radiocanadaca\"\n",
      "Topic: 4 \n",
      "Keywords: 0.036*\"factual\" + 0.023*\"false\" + 0.023*\"coronavirus\" + 0.018*\"macron\" + 0.014*\"no,\" + 0.014*\"liberation\" + 0.014*\"extras\" + 0.014*\"applauded\" + 0.014*\"pantin\" + 0.009*\"april\"\n",
      "Topic: 5 \n",
      "Keywords: 0.026*\"factual\" + 0.021*\"coronavirus\" + 0.017*\"false\" + 0.016*\"vaccine\" + 0.016*\"liberation\" + 0.011*\"no,\" + 0.011*\"april\" + 0.011*\"new\" + 0.011*\"states\" + 0.011*\"video\"\n",
      "Topic: 6 \n",
      "Keywords: 0.022*\"19\" + 0.015*\"coronavirus\" + 0.015*\"raoult\" + 0.015*\"africa\" + 0.015*\"false\" + 0.008*\"china\" + 0.008*\"5g\" + 0.008*\"created\" + 0.008*\"viral\" + 0.008*\"united\"\n",
      "Topic: 7 \n",
      "Keywords: 0.038*\"factual\" + 0.034*\"coronavirus\" + 0.030*\"false\" + 0.015*\"video\" + 0.012*\"vaccine\" + 0.012*\"china\" + 0.012*\"proven\" + 0.012*\"19\" + 0.008*\"agency\" + 0.008*\"covid19\"\n",
      "Topic: 8 \n",
      "Keywords: 0.036*\"coronavirus\" + 0.026*\"liberation\" + 0.021*\"covid\" + 0.021*\"19\" + 0.021*\"factual\" + 0.016*\"true\" + 0.011*\"false\" + 0.011*\"radiocanadaca\" + 0.011*\"made\" + 0.011*\"hydroxychloroquine\"\n",
      "Topic: 9 \n",
      "Keywords: 0.029*\"factual\" + 0.022*\"no,\" + 0.015*\"video\" + 0.015*\"covidorganics\" + 0.015*\"show\" + 0.015*\"hospital\" + 0.015*\"false\" + 0.008*\"liberation\" + 0.008*\"france\" + 0.008*\"19\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pshing/opt/anaconda3/lib/python3.9/site-packages/pyLDAvis/_prepare.py:243: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only.\n",
      "  default_term_info = default_term_info.sort_values(\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('fr_False_tran.csv')\n",
    "\n",
    "# Define stop words\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# Define preprocessing function for source_title column\n",
    "def preprocess_text(text):\n",
    "    words = text.lower().split()\n",
    "    filtered_words = [word for word in words if word not in stop_words]\n",
    "    return ' '.join(filtered_words)\n",
    "\n",
    "# Apply preprocessing to source_title column\n",
    "data['processed_text'] = data['source_title_translated'].apply(preprocess_text)\n",
    "\n",
    "# Create document-term matrix\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(data['processed_text'])\n",
    "\n",
    "processed_docs = data['processed_text'].apply(lambda x: x.split())\n",
    "\n",
    "# Create the gensim Dictionary object\n",
    "Dictionary = corpora.Dictionary(processed_docs)\n",
    "\n",
    "# Convert the preprocessed documents into a gensim corpus\n",
    "corpus = [Dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "\n",
    "# Train the LDA model\n",
    "lda_model = models.LdaModel(corpus=corpus, num_topics=10, id2word=Dictionary, passes=10, random_state=42)\n",
    "\n",
    "# Print the top 10 keywords for each topic\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print(\"Topic: {} \\nKeywords: {}\".format(idx, topic))\n",
    "\n",
    "# Visualize the topics\n",
    "lda_visualization = gensimvis.prepare(lda_model, corpus, Dictionary)\n",
    "\n",
    "# Save the visualization to an HTML file\n",
    "pyLDAvis.save_html(lda_visualization, 'fr_content.html')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2dd6ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
